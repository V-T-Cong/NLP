{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqCKIKLJO8OC","executionInfo":{"status":"ok","timestamp":1684154672278,"user_tz":-420,"elapsed":4698,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"414ca33d-c837-4d0e-c90d-2fd78c25adf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_text\n","  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.13.0)\n","Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.4.8)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.2.2)\n","Installing collected packages: tensorflow_text\n","Successfully installed tensorflow_text-2.12.1\n"]}],"source":["pip install tensorflow_text"]},{"cell_type":"code","source":["import logging\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import tensorflow_text\n","import random\n","import re \n","import nltk\n","nltk.download('punkt')\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","import statistics\n","\n","from tensorflow import keras\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wksfjPHoPJhX","executionInfo":{"status":"ok","timestamp":1684165151246,"user_tz":-420,"elapsed":421,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"4a823fc8-6293-4301-9e85-07634979b635"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/NLP/vi_sents', 'r', encoding='utf-8') as f:\n","    vi_sentences = f.read().splitlines()\n","with open('/content/drive/MyDrive/NLP/en_sents', 'r', encoding='utf-8') as f:\n","    en_sentences = f.read().splitlines()"],"metadata":{"id":"gpbGYgVFParH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(vi_sentences)):\n","  vi_sentences[i] = vi_sentences[i][:].lower()"],"metadata":{"id":"L9e-CZBaPmbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vi_sentences[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzdAxNLyPoho","executionInfo":{"status":"ok","timestamp":1684154681435,"user_tz":-420,"elapsed":10,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"b0ba739c-cf4a-41ae-ba55-f2e7ad0308b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['xin vui lòng đặt người quét rác trong tủ chổi', 'im lặng một lát', 'đọc này', 'tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta.', 'tình bạn bao gồm sự hiểu biết lẫn nhau', 'ngày mai bạn có đến không', 'nhìn thấy vấn đề này ngay lập tức, bạn sẽ?', 'tôi đã cho bạn bè của tôi xem những tấm bưu thiếp hình ảnh.', 'mary là em út trong ba chị em', 'anh ấy có hai người dì ở bên mẹ.']\n"]}]},{"cell_type":"code","source":["for i in range(len(en_sentences)):\n","  en_sentences[i] = en_sentences[i][:].lower()"],"metadata":{"id":"gVRwcg5OPrS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(en_sentences[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4ep26vdPs4n","executionInfo":{"status":"ok","timestamp":1684154681435,"user_tz":-420,"elapsed":8,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"2fc1d984-3750-4c9a-dc44-3cf02c6a0887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['please put the dustpan in the broom closet', 'be quiet for a moment.', 'read this', 'tom persuaded the store manager to give him back his money.', 'friendship consists of mutual understanding', 'are you going to come tomorrow?', 'see to this matter right away, will you?', 'i showed my friends these picture postcards.', 'mary is the youngest of the three sisters', \"he has two aunts on his mother's side.\"]\n"]}]},{"cell_type":"code","source":["for i in range(len(vi_sentences)):\n","  vi_sentences[i] = re.sub(r'[^\\w\\s]', '', vi_sentences[i])\n","\n","vi_sentences[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1wadz-LPump","executionInfo":{"status":"ok","timestamp":1684154681435,"user_tz":-420,"elapsed":6,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"205579dd-f01b-4e83-e34a-3b26c02dc7ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['xin vui lòng đặt người quét rác trong tủ chổi',\n"," 'im lặng một lát',\n"," 'đọc này',\n"," 'tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta',\n"," 'tình bạn bao gồm sự hiểu biết lẫn nhau',\n"," 'ngày mai bạn có đến không',\n"," 'nhìn thấy vấn đề này ngay lập tức bạn sẽ',\n"," 'tôi đã cho bạn bè của tôi xem những tấm bưu thiếp hình ảnh',\n"," 'mary là em út trong ba chị em',\n"," 'anh ấy có hai người dì ở bên mẹ']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["for i in range(len(en_sentences)):\n","  en_sentences[i] = re.sub(r'[^\\w\\s]', '', en_sentences[i])\n","\n","en_sentences[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-SzsHRRePypO","executionInfo":{"status":"ok","timestamp":1684154681435,"user_tz":-420,"elapsed":5,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"940f74ee-4e9d-4cc4-d262-f9fc968f6b3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['please put the dustpan in the broom closet',\n"," 'be quiet for a moment',\n"," 'read this',\n"," 'tom persuaded the store manager to give him back his money',\n"," 'friendship consists of mutual understanding',\n"," 'are you going to come tomorrow',\n"," 'see to this matter right away will you',\n"," 'i showed my friends these picture postcards',\n"," 'mary is the youngest of the three sisters',\n"," 'he has two aunts on his mothers side']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["for i in range(len(vi_sentences)):\n","\tvi_sentences[i] = '[start] ' + vi_sentences[i] + ' [end]'"],"metadata":{"id":"7DtnBeLXP1Tm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vi_sentences[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFVXWIsXP4Jf","executionInfo":{"status":"ok","timestamp":1684154682187,"user_tz":-420,"elapsed":8,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"ed7c8030-43b1-49c1-d948-bb9071efff13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[start] xin vui lòng đặt người quét rác trong tủ chổi [end]', '[start] im lặng một lát [end]', '[start] đọc này [end]', '[start] tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta [end]', '[start] tình bạn bao gồm sự hiểu biết lẫn nhau [end]', '[start] ngày mai bạn có đến không [end]', '[start] nhìn thấy vấn đề này ngay lập tức bạn sẽ [end]', '[start] tôi đã cho bạn bè của tôi xem những tấm bưu thiếp hình ảnh [end]', '[start] mary là em út trong ba chị em [end]', '[start] anh ấy có hai người dì ở bên mẹ [end]']\n"]}]},{"cell_type":"code","source":["concatenated = []\n","\n","for i in range(len(en_sentences)):\n","    sentence_pair = (en_sentences[i], vi_sentences[i])\n","    concatenated.append(sentence_pair)"],"metadata":{"id":"Gusz1AULP57N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","for _ in range(15):\n","    print(random.choice(concatenated))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wnC9CfjP83-","executionInfo":{"status":"ok","timestamp":1684154682187,"user_tz":-420,"elapsed":7,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"e4ca53d6-d513-4c03-a005-b29364591039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('dont start doing that', '[start] đừng bắt đầu làm điều đó [end]')\n","('please help me in the kitchen', '[start] xin hãy giúp tôi trong nhà bếp [end]')\n","('boys are more aggressive than girls', '[start] con trai hung dữ hơn con gái [end]')\n","('tom didnt need to use the knife i lent him', '[start] tom không cần dùng dao tôi cho anh ta mượn [end]')\n","('he is from the united states', '[start] anh ta đến từ nước mĩ [end]')\n","('this desk cost me 20000 yen', '[start] cái bàn này có giá 20000 yên [end]')\n","('im excited', '[start] tôi rất phấn khích [end]')\n","('i have to get that', '[start] tôi phải lấy nó [end]')\n","('youre going to need your umbrella', '[start] bạn sẽ cần chiếc ô của bạn [end]')\n","('which of those girls do you like', '[start] bạn thích cô gái nào [end]')\n","('i never knew you felt that way', '[start] tôi không bao giờ biết bạn cảm thấy như vậy [end]')\n","('i like baseball what sport do you like', '[start] tôi thích bóng chày bạn thích môn thể thao nào [end]')\n","('i bought a slow cooker', '[start] tôi đã mua một cái nồi nấu chậm [end]')\n","('tom is still talking to mary', '[start] tom vẫn đang nói chuyện với mary [end]')\n","('wheres the airport', '[start] sân bay ở đâu [end]')\n"]}]},{"cell_type":"code","source":["random.shuffle(concatenated)\n","num_val_samples = int(0.15 * len(concatenated))\n","num_train_samples = len(concatenated) - 2 * num_val_samples\n","train_pairs = concatenated[:num_train_samples]\n","val_pairs = concatenated[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = concatenated[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(concatenated)} total pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjiaxiI6P-Vf","executionInfo":{"status":"ok","timestamp":1684154682187,"user_tz":-420,"elapsed":5,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"81f8eabe-56dd-4245-9ac6-433ce3e22d92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["254090 total pairs\n","177864 training pairs\n","38113 validation pairs\n","38113 test pairs\n"]}]},{"cell_type":"code","source":["import string\n","\n","strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\") \n","\n","vocab_size = 15000\n","sequence_length = 20\n","batch_size = 64\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","\n","en_vectorization = TextVectorization(\n","    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",")\n","vi_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_en_texts = [pair[0] for pair in train_pairs]\n","train_vi_texts = [pair[1] for pair in train_pairs]\n","en_vectorization.adapt(train_en_texts)\n","vi_vectorization.adapt(train_vi_texts)"],"metadata":{"id":"xwWIyj1kQFu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_dataset(en, vi):\n","    en = en_vectorization(en)\n","    vi = vi_vectorization(vi)\n","    return ({\"encoder_inputs\": en, \"decoder_inputs\": vi[:, :-1],}, vi[:, 1:])\n","\n","\n","def make_dataset(pairs):\n","    en_texts, vi_texts = zip(*pairs)\n","    en_texts = list(en_texts)\n","    vi_texts = list(vi_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((en_texts, vi_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"metadata":{"id":"F41I3WF3QIxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaLxDE7AQKyg","executionInfo":{"status":"ok","timestamp":1684154751733,"user_tz":-420,"elapsed":1257,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"9ccc2134-158c-4949-f552-06cf02fe619e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n"]}]},{"cell_type":"code","source":["\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)"],"metadata":{"id":"HmxxYwvDQN4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"],"metadata":{"id":"jYiJaNRamNcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 20  # This should be at least 30 for convergence\n","\n","transformer.summary()\n","transformer.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmQAFb0DQYwR","executionInfo":{"status":"ok","timestamp":1684158622892,"user_tz":-420,"elapsed":3870192,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"f3d4bfed-c8bf-43ef-873c-567d12e61b66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n"," alEmbedding)                                                                                     \n","                                                                                                  \n"," decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n"," erEncoder)                                                                                       \n","                                                                                                  \n"," model_1 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n","                                                                  'transformer_encoder[0][0]']    \n","                                                                                                  \n","==================================================================================================\n","Total params: 19,960,216\n","Trainable params: 19,960,216\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/20\n","2780/2780 [==============================] - 221s 75ms/step - loss: 2.4210 - accuracy: 0.5981 - val_loss: 1.6093 - val_accuracy: 0.7065\n","Epoch 2/20\n","2780/2780 [==============================] - 187s 67ms/step - loss: 1.5942 - accuracy: 0.7108 - val_loss: 1.3763 - val_accuracy: 0.7438\n","Epoch 3/20\n","2780/2780 [==============================] - 185s 66ms/step - loss: 1.3948 - accuracy: 0.7436 - val_loss: 1.3244 - val_accuracy: 0.7536\n","Epoch 4/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 1.2776 - accuracy: 0.7639 - val_loss: 1.2666 - val_accuracy: 0.7673\n","Epoch 5/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 1.1762 - accuracy: 0.7816 - val_loss: 1.1844 - val_accuracy: 0.7837\n","Epoch 6/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 1.0730 - accuracy: 0.7990 - val_loss: 1.1309 - val_accuracy: 0.7927\n","Epoch 7/20\n","2780/2780 [==============================] - 183s 66ms/step - loss: 0.9966 - accuracy: 0.8122 - val_loss: 1.1127 - val_accuracy: 0.7974\n","Epoch 8/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.9350 - accuracy: 0.8224 - val_loss: 1.0702 - val_accuracy: 0.8074\n","Epoch 9/20\n","2780/2780 [==============================] - 183s 66ms/step - loss: 0.8870 - accuracy: 0.8308 - val_loss: 1.0595 - val_accuracy: 0.8094\n","Epoch 10/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.8448 - accuracy: 0.8380 - val_loss: 1.0417 - val_accuracy: 0.8135\n","Epoch 11/20\n","2780/2780 [==============================] - 183s 66ms/step - loss: 0.8065 - accuracy: 0.8446 - val_loss: 1.0343 - val_accuracy: 0.8157\n","Epoch 12/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.7751 - accuracy: 0.8500 - val_loss: 1.0237 - val_accuracy: 0.8182\n","Epoch 13/20\n","2780/2780 [==============================] - 183s 66ms/step - loss: 0.7482 - accuracy: 0.8547 - val_loss: 1.0312 - val_accuracy: 0.8200\n","Epoch 14/20\n","2780/2780 [==============================] - 183s 66ms/step - loss: 0.7241 - accuracy: 0.8591 - val_loss: 1.0325 - val_accuracy: 0.8193\n","Epoch 15/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.7035 - accuracy: 0.8625 - val_loss: 1.0404 - val_accuracy: 0.8224\n","Epoch 16/20\n","2780/2780 [==============================] - 185s 67ms/step - loss: 0.6861 - accuracy: 0.8658 - val_loss: 1.0579 - val_accuracy: 0.8196\n","Epoch 17/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.6707 - accuracy: 0.8685 - val_loss: 1.0081 - val_accuracy: 0.8251\n","Epoch 18/20\n","2780/2780 [==============================] - 185s 67ms/step - loss: 0.6552 - accuracy: 0.8716 - val_loss: 1.0300 - val_accuracy: 0.8232\n","Epoch 19/20\n","2780/2780 [==============================] - 184s 66ms/step - loss: 0.6430 - accuracy: 0.8737 - val_loss: 1.0339 - val_accuracy: 0.8262\n","Epoch 20/20\n","2780/2780 [==============================] - 187s 67ms/step - loss: 0.6326 - accuracy: 0.8757 - val_loss: 1.0448 - val_accuracy: 0.8258\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efeb82ff640>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["vi_vocab = vi_vectorization.get_vocabulary()\n","vi_index_lookup = dict(zip(range(len(vi_vocab)), vi_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = en_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = vi_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = vi_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence"],"metadata":{"id":"RbSKa0oswk9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_eng_texts = [pair[0] for pair in test_pairs]\n","breaktext = []\n","\n","\n","bleu_scores = []\n","test_vi_texts = [pair[1] for pair in test_pairs]\n","\n","for i in range(1000):\n","    input_sentence = test_eng_texts[i]\n","    translated = decode_sequence(input_sentence)\n","    breaktext.append(translated)\n","    bleu_scores.append(sentence_bleu(translated, input_sentence))\n","\n","print(statistics.mean(bleu_scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEEhwdIpxwm4","executionInfo":{"status":"ok","timestamp":1684167010327,"user_tz":-420,"elapsed":540181,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"6d3841bc-5264-44b7-ce42-e188a3fd8933"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["1.3947328944655678e-231\n"]}]},{"cell_type":"code","source":["for i in range(20):\n","  print(breaktext[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QznBGfhwzCL-","executionInfo":{"status":"ok","timestamp":1684161488777,"user_tz":-420,"elapsed":979,"user":{"displayName":"Công Võ Thành","userId":"01897825053192887916"}},"outputId":"efd3c36c-4d80-4ed7-b4d3-f413b584835a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[start] các thí nghiệm có nhiều hơn hơi du lịch [end]\n","[start] tôi không quan tâm nhiều cho loại điều này [end]\n","[start] nó làm tôi nhớ đến những ngày xưa tốt đẹp [end]\n","[start] quá nhiều nấu ăn rất rất đau làm hỏng [end]\n","[start] những ngày đang kéo từ từ [end]\n","[start] ông được sinh ra là một họa sĩ [end]\n","[start] khi nào ngày lớn [end]\n","[start] bác sĩ đơn cho nó cho cô [end]\n","[start] mary không cho phép uống em gái của mình [end]\n","[start] tom hỏi mary ai đã đưa cho cô ấy hình ảnh của mình [end]\n","[start] tôi không bao giờ có thể thay thế tom [end]\n","[start] nếu bạn là hóa đơn xin hóa đơn bạn sẽ không nói vậy [end]\n","[start] tôi thậm chí không nghĩ về nó nữa [end]\n","[start] tom đã không chơi hanako ở châu á trong thời đại [end]\n","[start] tom đã làm tốt ở đây [end]\n","[start] tôi không biết bạn có thể nói tiếng pháp [end]\n","[start] tôi đã bị đánh cắp đồng hồ [end]\n","[start] người ngu ngốc hơn một đứa trẻ là dễ thương của anh ta [end]\n","[start] trước khi bạn chỉ trích một người đàn ông bạn nên đi bằng giày đi được một dặm [end]\n","[start] lễ hội đã đến kết thúc [end]\n"]}]}]}